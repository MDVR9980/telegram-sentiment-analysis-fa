# ğŸ‡®ğŸ‡· Persian Sentiment Analysis on Telegram (5-Year Historical Study)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![NLP](https://img.shields.io/badge/NLP-Llama3-orange?style=for-the-badge)
![Ollama](https://img.shields.io/badge/Backend-Ollama-white?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Completed-green?style=for-the-badge)

## ğŸ“‹ Project Overview

This project involves a comprehensive **Natural Language Processing (NLP)** analysis of Persian social media sentiment over a 5-year historical period (**1399â€“1404 SH** / **2020â€“2025 AD**).

The primary objective is to analyze public mood trends on **Telegram**, utilizing **Large Language Models (LLMs)** locally. By leveraging **Meta's Llama 3 (8B)** via **Ollama**, this project classifies thousands of posts into precise emotional categories, handling the linguistic nuances of the Persian language (Farsi), including slang, sarcasm, and cultural context.

### ğŸ¯ Key Objectives
*   **Historical Data Mining:** Extracting 5 years of messages, reactions, and metadata from 5 major public channels using `Telethon`.
*   **Persian NLP Pipeline:** Modular preprocessing using `Hazm` and Regex for text normalization.
*   **LLM-Based Classification:** Using a **custom-engineered Persian System Prompt** to detect complex sentiments (e.g., distinguishing "Dark Humor" from "Sadness").
*   **Visual Analytics:** Generating time-series trends and "Hope vs. Despair" statistical ratios.

---

## ğŸ“‚ Repository Structure

The project follows a **modular architecture** to ensure maintainability and scalability.

```text
t-sentiment-analysis-fa/
â”‚
â”œâ”€â”€ data/                      # Data Storage
â”‚   â”œâ”€â”€ processed/             # Cleaned data, Checkpoints, and Final Results
â”‚   â”œâ”€â”€ kafiha_messages.csv    # Raw Data (Channel 1)
â”‚   â”œâ”€â”€ bbcpersian_messages.csv# Raw Data (Channel 2)
â”‚   â””â”€â”€ ...                    # Other channel datasets
â”‚
â”œâ”€â”€ scripts/                   # Source Code Modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ preprocessor.py        # Core Logic: Text Cleaning & Normalization Class
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks for Execution
â”‚   â”œâ”€â”€ sentiment_analysis.ipynb       # ğŸ§ª Test Notebook (Rapid prototyping on 10 samples)
â”‚   â””â”€â”€ full_analysis_pipeline.ipynb   # ğŸš€ Production Notebook (Full dataset + Checkpointing)
â”‚
â”œâ”€â”€ results/                   # Output Visualizations & Reports
â”‚   â”œâ”€â”€ trend_plot.png         # 5-Year Sentiment Trend Line
â”‚   â””â”€â”€ mood_bar.png           # Channel comparison bar charts
â”‚
â”œâ”€â”€ requirements.txt           # Python Dependencies
â””â”€â”€ README.md                  # Project Documentation

## ğŸ› ï¸ Methodology & Tech Stack

### 1. Data Collection (Scraping)
We utilized the **Telethon API** to scrape historical data. The scraper fetches:
*   **Text Content:** The body of the message.
*   **Metadata:** Timestamp (exact date/time), Views, and Forward counts.
*   **Reactions:** Emoji reactions (e.g., ğŸ‘, ğŸ˜¢, â¤ï¸) which provide critical context for sentiment verification.

### 2. Preprocessing (The `scripts/preprocessor.py` Module)
Raw social media text is noisy. We implemented a robust cleaning pipeline:
*   **HTML & URL Removal:** Stripping `<tags>` and `http://` links.
*   **Noise Reduction:** Removing numbers (as per assignment requirement) and non-Persian symbols.
*   **Normalization:** Using the **Hazm** library to standardize Persian characters (e.g., converting Arabic 'ÙŠ' and 'Ùƒ' to Persian 'ÛŒ' and 'Ú©', and handling zero-width spaces).

### 3. Sentiment Classification (The "Brain")
We use **Llama 3** running locally. The core innovation lies in the **Prompt Engineering**:

*   **The Challenge:** Persian social media often uses "Dark Humor" (Ø·Ù†Ø² ØªÙ„Ø®) where a funny text actually implies sadness or anger regarding economic situations.
*   **The Solution:** A **Native Persian System Prompt** was designed to instruct the model to interpret these nuances.

**Taxonomy (Labels):**
*   **Ø®ÙˆØ´Ø­Ø§Ù„ (Happy):** Joy, success, pure humor.
*   **Ù†Ø§Ø±Ø§Ø­Øª (Sad):** Grief, dark humor, complaints about life.
*   **Ø¹ØµØ¨Ø§Ù†ÛŒ (Angry):** Rage, protest, harsh criticism.
*   **Ù…Ø¶Ø·Ø±Ø¨ (Anxious):** Panic, immediate stress.
*   **Ù†Ú¯Ø±Ø§Ù† (Worried):** Fear of the future, uncertainty.
*   **Ø®Ù†Ø«ÛŒ (Neutral):** News, advertisements, factual statements.

---

## ğŸš€ Installation & Usage Guide

### Prerequisites
*   **Python 3.9+**
*   **Ollama:** Download and install from [ollama.com](https://ollama.com).
*   **Hardware:** A GPU with at least 4GB VRAM is recommended (e.g., GTX 1650), though it runs on CPU/RAM with slower inference.

### Step 1: Clone & Install
```bash
git clone https://github.com/YOUR_USERNAME/t-sentiment-analysis-fa.git
cd t-sentiment-analysis-fa
pip install -r requirements.txt

### Step 2: Setup the Model
Launch the Ollama server and pull the Llama 3 model:

```bash
# Open a terminal and run:
ollama serve

# In a separate terminal:
ollama pull llama3

### Step 3: Run the Analysis

#### ğŸ…°ï¸ Option A: Quick Test (Local Machine)
To verify the pipeline works on a small subset (10 posts):
1.  Launch Jupyter:
    ```bash
    jupyter notebook
    ```
2.  Open `notebooks/sentiment_analysis.ipynb`.
3.  Run all cells. The result will be saved in `data/processed/test_results.csv`.

#### ğŸ…±ï¸ Option B: Full Production Run (Server/University Lab)
To process the entire 5-year dataset:
1.  Open `notebooks/full_analysis_pipeline.ipynb`.
2.  Run the notebook.

> **Note:** This notebook includes a **Checkpoint System**. If the process is interrupted (e.g., power outage), simply restart the cell, and it will automatically resume from the last saved batch.

---

## ğŸ“Š Results & Visualization

The pipeline generates two key types of insights in the `results/` directory:

### 1. Time-Series Trend Analysis
A line chart tracking the fluctuation of sentiments (Happy vs. Sad/Angry) over 5 years. This highlights correlations between real-world events (e.g., elections, economic shifts) and online public mood.

### 2. Hope vs. Despair Ratio
A statistical breakdown per channel, grouping sentiments into:
*   **Positive/Hope:** `['Ø®ÙˆØ´Ø­Ø§Ù„']`
*   **Negative/Despair:** `['Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†', 'Ù…Ø¶Ø·Ø±Ø¨']`
*   **Neutral:** `['Ø®Ù†Ø«ÛŒ']`

---

## âš™ï¸ Configuration

You can modify the `notebooks` to change the configuration:

```python
MODEL_NAME = "llama3"   # You can switch to "llama2" or "mistral" if downloaded
BATCH_SIZE = 100        # Adjust batch saving interval
SOURCES = [...]         # Add or remove target channels

## ğŸ“œ License
This project is created for the **Advanced NLP Course (Fall 2025)**.