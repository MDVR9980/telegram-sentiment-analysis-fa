{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9039f123",
   "metadata": {},
   "source": [
    "# Full Scale Sentiment Analysis Pipeline\n",
    "## **Course:** Advanced NLP\n",
    "### This notebook processes all data, handles interruptions via checkpointing, and generates visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb38b00",
   "metadata": {},
   "source": [
    "## Add scripts path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.preprocessor import TextPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82eba7",
   "metadata": {},
   "source": [
    "## Set visual style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e66b7",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_DIR = \"../data/processed\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_FILE = os.path.join(PROCESSED_DIR, \"full_data_checkpoint.csv\")\n",
    "MODEL_NAME = \"llama3\"\n",
    "SOURCES = [\"kafiha\", \"TweetyChannel\", \"radiofarda\", \"iranintlTV\", \"bbcpersian\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f7af8",
   "metadata": {},
   "source": [
    "## 2. Data Aggregation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for source in SOURCES:\n",
    "    file_path = os.path.join(DATA_DIR, f\"{source}_messages.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        df_temp['source'] = source\n",
    "        all_dfs.append(df_temp)\n",
    "\n",
    "full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "full_df['date'] = pd.to_datetime(full_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eeccd",
   "metadata": {},
   "source": [
    "## Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['text'] = full_df['text'].fillna('')\n",
    "full_df['emoji_reactions'] = full_df['emoji_reactions'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305391a0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac462aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "print(\"Cleaning text (this may take a while)...\")\n",
    "tqdm.pandas()\n",
    "full_df['clean_post_text'] = full_df['text'].progress_apply(preprocessor.clean_text)\n",
    "full_df['clean_reactions'] = full_df['emoji_reactions'].apply(preprocessor.clean_reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e047e",
   "metadata": {},
   "source": [
    "## Filter noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce117390",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[full_df['clean_post_text'].str.len() > 5].reset_index(drop=True)\n",
    "print(f\"Ready to process {len(full_df)} posts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881d5aa",
   "metadata": {},
   "source": [
    "## 3. Inference Loop (With Checkpointing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de690a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(text, reactions):\n",
    "    \"\"\"\n",
    "    Uses Few-Shot Prompting for the Full Pipeline.\n",
    "    \"\"\"\n",
    "    prompt_text = f\"متن پست: {text}\\nواکنش‌ها: {reactions}\"\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"تو یک تحلیلگر دقیق احساسات فارسی هستی. بر اساس مثال‌های زیر، پست جدید را طبقه‌بندی کن.\\n\"\n",
    "        \"دسته‌بندی‌ها: ['خوشحال', 'ناراحت', 'عصبانی', 'مضطرب', 'خنثی', 'نگران']\\n\\n\"\n",
    "        \"--- مثال‌های آموزشی ---\\n\"\n",
    "        \"مثال ۱ (تبلیغات/خبر): تور استانبول ویژه بلک فرایدی. -> خنثی\\n\"\n",
    "        \"مثال ۲ (غم/دلتنگی): فراموش کردنت سخته عزیزم. -> ناراحت\\n\"\n",
    "        \"مثال ۳ (طنز/موفقیت): وای چقدر خوشحالم تموم شد. -> خوشحال\\n\"\n",
    "        \"مثال ۴ (خشم/اعتراض): چرا وضعیت اینترنت اینطوریه؟ -> عصبانی\\n\"\n",
    "        \"مثال ۵ (نگرانی/پول): آخر ماه شد و حقوق نریختن. -> نگران\\n\"\n",
    "        \"--- پایان مثال‌ها ---\\n\"\n",
    "        \"فقط برچسب را بنویس.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt_text},\n",
    "        ])\n",
    "        label = response['message']['content'].strip()\n",
    "        valid = ['خوشحال', 'ناراحت', 'عصبانی', 'مضطرب', 'خنثی', 'نگران']\n",
    "        for v in valid:\n",
    "            if v in label: return v\n",
    "        return \"خنثی\"\n",
    "    except:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc73eda",
   "metadata": {},
   "source": [
    "## Resume Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    processed_df = pd.read_csv(CHECKPOINT_FILE)\n",
    "    start_idx = len(processed_df)\n",
    "    print(f\"Resuming from index {start_idx}...\")\n",
    "else:\n",
    "    processed_df = pd.DataFrame()\n",
    "    start_idx = 0\n",
    "\n",
    "batch_size = 50\n",
    "new_rows = []\n",
    "\n",
    "print(\"Starting/Resuming Inference...\")\n",
    "for i in tqdm(range(start_idx, len(full_df))):\n",
    "    row = full_df.iloc[i]\n",
    "    sentiment = get_sentiment_label(row['clean_post_text'], row['clean_reactions'])\n",
    "    \n",
    "    r_dict = row.to_dict()\n",
    "    r_dict['sentiment'] = sentiment\n",
    "    new_rows.append(r_dict)\n",
    "    \n",
    "    if len(new_rows) >= batch_size:\n",
    "        temp_df = pd.DataFrame(new_rows)\n",
    "        processed_df = pd.concat([processed_df, temp_df], ignore_index=True) if not processed_df.empty else temp_df\n",
    "        processed_df.to_csv(CHECKPOINT_FILE, index=False, encoding='utf-8-sig')\n",
    "        new_rows = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995a035",
   "metadata": {},
   "source": [
    "## Save remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e964493",
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_rows:\n",
    "    temp_df = pd.DataFrame(new_rows)\n",
    "    processed_df = pd.concat([processed_df, temp_df], ignore_index=True) if not processed_df.empty else temp_df\n",
    "    processed_df.to_csv(CHECKPOINT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25f394",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c850c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CHECKPOINT_FILE)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month_year'] = df['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae235eed",
   "metadata": {},
   "source": [
    "## 1. Trend Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849aca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = df.groupby(['month_year', 'sentiment']).size().unstack(fill_value=0).resample('M').sum()\n",
    "plt.figure(figsize=(14, 7))\n",
    "for col in ['خوشحال', 'ناراحت', 'عصبانی', 'نگران']:\n",
    "    if col in trend.columns:\n",
    "        plt.plot(trend.index.astype(str), trend[col], label=col)\n",
    "plt.title(\"Sentiment Trends (2020-2025)\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"trend_plot.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31a55d",
   "metadata": {},
   "source": [
    "## 2. Hope vs Despair Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mood(s):\n",
    "    if s == 'خوشحال': return 'Hope/Positive'\n",
    "    if s in ['ناراحت', 'عصبانی', 'نگران', 'مضطرب']: return 'Despair/Negative'\n",
    "    return 'Neutral'\n",
    "\n",
    "df['mood'] = df['sentiment'].apply(map_mood)\n",
    "mood_counts = df.groupby(['source', 'mood']).size().unstack(fill_value=0)\n",
    "mood_counts.plot(kind='bar', color=['red', 'green', 'gray'], figsize=(10,6))\n",
    "plt.title(\"Mood Analysis by Channel\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"mood_bar.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
