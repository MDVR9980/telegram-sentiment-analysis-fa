{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9039f123",
   "metadata": {},
   "source": [
    "# Full Scale Sentiment Analysis (Stateless & Robust)\n",
    "## **Course:** Advanced NLP (Fall 2025)\n",
    "\n",
    "## This notebook implements a production-grade pipeline designed for large datasets (950k+ posts).\n",
    "## Key Features:\n",
    "### 1. **Stateless Inference:** Each post is processed independently. The LLM retains zero memory of previous posts.\n",
    "### 2. **Robust Checkpointing:** Results are saved incrementally. If the system crashes, execution resumes automatically from the last saved row.\n",
    "### 3. **Memory Efficient:** Processes data in batches to respect RAM limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16a8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb38b00",
   "metadata": {},
   "source": [
    "## Add scripts path for modular imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c43a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.preprocessor import TextPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82eba7",
   "metadata": {},
   "source": [
    "## Visualization Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8383ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e66b7",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bef05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_DIR = \"../data/processed\"\n",
    "RESULTS_DIR = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787dea7c",
   "metadata": {},
   "source": [
    "### Create directories if they don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c866354",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c3c529",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3275d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DATA_FILE = os.path.join(PROCESSED_DIR, \"master_cleaned_dataset.csv\")\n",
    "FINAL_RESULTS_FILE = os.path.join(PROCESSED_DIR, \"final_sentiment_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911df2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama3\"\n",
    "BATCH_SIZE = 100  # Save to disk every 100 posts\n",
    "SOURCES = [\"kafiha\", \"TweetyChannel\", \"radiofarda\", \"iranintlTV\", \"bbcpersian\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c813a",
   "metadata": {},
   "source": [
    "## 2. Data Preparation (Load, Clean, Filter)\n",
    "### To ensure indices align perfectly for resuming, we first create a **Master Cleaned Dataset**.\n",
    "### If this file already exists, we skip this step to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb32c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Master dataset found at ../data/processed/master_cleaned_dataset.csv. Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6058/2257424174.py:3: DtypeWarning: Columns (6,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_df = pd.read_csv(MASTER_DATA_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ready to process 843971 posts.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(MASTER_DATA_FILE):\n",
    "    print(f\"âœ… Master dataset found at {MASTER_DATA_FILE}. Loading...\")\n",
    "    full_df = pd.read_csv(MASTER_DATA_FILE)\n",
    "else:\n",
    "    print(\"âš ï¸ Master dataset not found. Building from scratch...\")\n",
    "    \n",
    "    # 1. Load Raw Data\n",
    "    all_dfs = []\n",
    "    for source in SOURCES:\n",
    "        path = os.path.join(DATA_DIR, f\"{source}_messages.csv\")\n",
    "        if os.path.exists(path):\n",
    "            print(f\"   - Loading {source}...\")\n",
    "            temp_df = pd.read_csv(path)\n",
    "            temp_df['source'] = source\n",
    "            all_dfs.append(temp_df)\n",
    "    \n",
    "    if not all_dfs:\n",
    "        raise FileNotFoundError(\"No source CSV files found in data/ directory!\")\n",
    "        \n",
    "    full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    # 2. Preprocessing\n",
    "    print(\"   - Initializing Preprocessor...\")\n",
    "    preprocessor = TextPreprocessor()\n",
    "    \n",
    "    # Fill NaNs\n",
    "    full_df['text'] = full_df['text'].fillna('')\n",
    "    full_df['emoji_reactions'] = full_df['emoji_reactions'].fillna('')\n",
    "    \n",
    "    print(\"   - Cleaning text (This might take a few minutes for 900k+ rows)...\")\n",
    "    tqdm.pandas(desc=\"Cleaning\")\n",
    "    full_df['clean_post_text'] = full_df['text'].progress_apply(preprocessor.clean_text)\n",
    "    full_df['clean_reactions'] = full_df['emoji_reactions'].apply(preprocessor.clean_reactions)\n",
    "    \n",
    "    # 3. Filtering (Remove short/empty texts)\n",
    "    initial_len = len(full_df)\n",
    "    full_df = full_df[full_df['clean_post_text'].str.len() > 10].reset_index(drop=True)\n",
    "    print(f\"   - Filtered {initial_len - len(full_df)} short/empty posts.\")\n",
    "    \n",
    "    # 4. Save Master File\n",
    "    print(f\"   - Saving Master Dataset ({len(full_df)} rows)...\")\n",
    "    full_df.to_csv(MASTER_DATA_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"ğŸš€ Ready to process {len(full_df)} posts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f86f4",
   "metadata": {},
   "source": [
    "## 3. Stateless Inference Engine\n",
    "### We define the logic to query Llama 3.\n",
    "### **Important:** `messages` list is recreated inside the function every time to ensure **Zero Memory** of previous posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d567cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(text, reactions):\n",
    "    \"\"\"\n",
    "    Stateless Sentiment Analysis using Few-Shot Prompting.\n",
    "    Each call is independent. No context is shared between posts.\n",
    "    \"\"\"\n",
    "    prompt_text = f\"Ù…ØªÙ† Ù¾Ø³Øª: {text}\\nÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {reactions}\"\n",
    "    \n",
    "    # Optimized Few-Shot Prompt\n",
    "    system_prompt = (\n",
    "        \"ØªÙˆ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ù‚ÛŒÙ‚ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒ. Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ±ØŒ Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†.\\n\"\n",
    "        \"Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: ['Ø®ÙˆØ´Ø­Ø§Ù„', 'Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù…Ø¶Ø·Ø±Ø¨', 'Ø®Ù†Ø«ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†']\\n\\n\"\n",
    "        \"--- Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ ---\\n\"\n",
    "        \"Ù…Ø«Ø§Ù„ Û± (ØªØ¨Ù„ÛŒØºØ§Øª/Ø®Ø¨Ø±): ØªÙˆØ± Ø§Ø³ØªØ§Ù†Ø¨ÙˆÙ„ ÙˆÛŒÚ˜Ù‡ Ø¨Ù„Ú© ÙØ±Ø§ÛŒØ¯ÛŒ. -> Ø®Ù†Ø«ÛŒ\\n\"\n",
    "        \"Ù…Ø«Ø§Ù„ Û² (ØºÙ…/Ø¯Ù„ØªÙ†Ú¯ÛŒ): ÙØ±Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù†Øª Ø³Ø®ØªÙ‡ Ø¹Ø²ÛŒØ²Ù…. -> Ù†Ø§Ø±Ø§Ø­Øª\\n\"\n",
    "        \"Ù…Ø«Ø§Ù„ Û³ (Ø·Ù†Ø²/Ù…ÙˆÙÙ‚ÛŒØª): ÙˆØ§ÛŒ Ú†Ù‚Ø¯Ø± Ø®ÙˆØ´Ø­Ø§Ù„Ù… ØªÙ…ÙˆÙ… Ø´Ø¯. -> Ø®ÙˆØ´Ø­Ø§Ù„\\n\"\n",
    "        \"Ù…Ø«Ø§Ù„ Û´ (Ø®Ø´Ù…/Ø§Ø¹ØªØ±Ø§Ø¶): Ú†Ø±Ø§ ÙˆØ¶Ø¹ÛŒØª Ø§ÛŒÙ†ØªØ±Ù†Øª Ø§ÛŒÙ†Ø·ÙˆØ±ÛŒÙ‡ØŸ -> Ø¹ØµØ¨Ø§Ù†ÛŒ\\n\"\n",
    "        \"Ù…Ø«Ø§Ù„ Ûµ (Ù†Ú¯Ø±Ø§Ù†ÛŒ/Ù¾ÙˆÙ„): Ø¢Ø®Ø± Ù…Ø§Ù‡ Ø´Ø¯ Ùˆ Ø­Ù‚ÙˆÙ‚ Ù†Ø±ÛŒØ®ØªÙ†. -> Ù†Ú¯Ø±Ø§Ù†\\n\"\n",
    "        \"--- Ù¾Ø§ÛŒØ§Ù† Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ ---\\n\"\n",
    "        \"ÙÙ‚Ø· Ø¨Ø±Ú†Ø³Ø¨ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Generate a fresh request (Stateless)\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt_text},\n",
    "        ])\n",
    "        \n",
    "        label = response['message']['content'].strip()\n",
    "        \n",
    "        # Basic Validation\n",
    "        valid_labels = ['Ø®ÙˆØ´Ø­Ø§Ù„', 'Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù…Ø¶Ø·Ø±Ø¨', 'Ø®Ù†Ø«ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†']\n",
    "        for v in valid_labels:\n",
    "            if v in label: return v\n",
    "        return \"Ø®Ù†Ø«ÛŒ\" # Fallback\n",
    "    except Exception as e:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12775e54",
   "metadata": {},
   "source": [
    "## 4. Main Execution Loop (With Resume Capability)\n",
    "### We check `final_sentiment_results.csv`. If it exists, we count the rows and skip that many in `full_df`.\n",
    "\n",
    "#### 1. Check Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d5aee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ Starting new analysis...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FINAL_RESULTS_FILE):\n",
    "    # Count lines in existing file to determine start index\n",
    "    # We substract 1 for the header\n",
    "    with open(FINAL_RESULTS_FILE, 'r', encoding='utf-8-sig') as f:\n",
    "        processed_count = sum(1 for _ in f) - 1\n",
    "    \n",
    "    # Determine mode\n",
    "    write_mode = 'a' # Append\n",
    "    header = False   # Don't write header again\n",
    "    start_index = processed_count\n",
    "    print(f\"ğŸ”„ Resuming from index {start_index}...\")\n",
    "else:\n",
    "    write_mode = 'w' # Write new\n",
    "    header = True    # Write header\n",
    "    start_index = 0\n",
    "    print(\"ğŸŸ¢ Starting new analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01cdcd",
   "metadata": {},
   "source": [
    "#### 2. Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b82ccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 29/843971 [01:08<555:55:25,  2.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m row \u001b[38;5;241m=\u001b[39m full_df\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Call LLM (Stateless)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentiment_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_post_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_reactions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Prepare Result Row\u001b[39;00m\n\u001b[1;32m     13\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg_id\u001b[39m\u001b[38;5;124m'\u001b[39m: row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg_id\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m: sentiment\n\u001b[1;32m     19\u001b[0m }\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mget_sentiment_label\u001b[0;34m(text, reactions)\u001b[0m\n\u001b[1;32m      9\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mØªÙˆ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ù‚ÛŒÙ‚ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒ. Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ±ØŒ Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mØ¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mØ®ÙˆØ´Ø­Ø§Ù„\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÙ†Ø§Ø±Ø§Ø­Øª\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mØ¹ØµØ¨Ø§Ù†ÛŒ\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÙ…Ø¶Ø·Ø±Ø¨\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mØ®Ù†Ø«ÛŒ\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÙ†Ú¯Ø±Ø§Ù†\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÙÙ‚Ø· Ø¨Ø±Ú†Ø³Ø¨ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Generate a fresh request (Stateless)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     label \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Basic Validation\u001b[39;00m\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/ollama/_client.py:365\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    319\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/ollama/_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/ollama/_client.py:129\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Public/ANLP/ai-env/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if start_index < len(full_df):\n",
    "    batch_buffer = []\n",
    "    \n",
    "    # Iterate from the last checkpoint\n",
    "    for i in tqdm(range(start_index, len(full_df)), desc=\"Processing\", initial=start_index, total=len(full_df)):\n",
    "        \n",
    "        row = full_df.iloc[i]\n",
    "        \n",
    "        # Call LLM (Stateless)\n",
    "        sentiment = get_sentiment_label(row['clean_post_text'], row['clean_reactions'])\n",
    "        \n",
    "        # Prepare Result Row\n",
    "        result_dict = {\n",
    "            'msg_id': row.get('msg_id'),\n",
    "            'date': row.get('date'),\n",
    "            'source': row.get('source'),\n",
    "            'clean_text': row['clean_post_text'], # Saving cleaned text to save space\n",
    "            'sentiment': sentiment\n",
    "        }\n",
    "        batch_buffer.append(result_dict)\n",
    "        \n",
    "        # 3. Save to Disk (Batch)\n",
    "        if len(batch_buffer) >= BATCH_SIZE:\n",
    "            df_batch = pd.DataFrame(batch_buffer)\n",
    "            df_batch.to_csv(FINAL_RESULTS_FILE, mode=write_mode, header=header, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            # Reset buffer and flags\n",
    "            batch_buffer = []\n",
    "            header = False # Never write header after first batch\n",
    "            write_mode = 'a' # Always append hereafter\n",
    "            \n",
    "    # 4. Save remaining items\n",
    "    if batch_buffer:\n",
    "        df_batch = pd.DataFrame(batch_buffer)\n",
    "        df_batch.to_csv(FINAL_RESULTS_FILE, mode=write_mode, header=header, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\nâœ… Analysis Complete! All rows processed.\")\n",
    "else:\n",
    "    print(\"\\nâœ… All rows were already processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4dead0",
   "metadata": {},
   "source": [
    "### 5. Visualization & Statistics\n",
    "#### Now we load the FINAL processed file and generate the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading final results for visualization...\")\n",
    "df_results = pd.read_csv(FINAL_RESULTS_FILE)\n",
    "df_results['date'] = pd.to_datetime(df_results['date'])\n",
    "df_results['month_year'] = df_results['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5adb4",
   "metadata": {},
   "source": [
    "## --- A. Trend Analysis (Time Series) ---\n",
    "### Group by Month and Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_data = df_results.groupby(['month_year', 'sentiment']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f299620",
   "metadata": {},
   "source": [
    "#### Filter for top 4 active sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['Ø®ÙˆØ´Ø­Ø§Ù„', 'Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†']\n",
    "existing_cols = [c for c in target_cols if c in trend_data.columns]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "trend_data[existing_cols].plot(kind='line', marker='o', figsize=(14, 7))\n",
    "plt.title(\"Sentiment Trends Over 5 Years (Monthly)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Post Count\")\n",
    "plt.legend(title=\"Sentiment\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"final_trend_analysis.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aaca8",
   "metadata": {},
   "source": [
    "## --- B. Hope vs. Despair (Ratio) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f02142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_mood(sent):\n",
    "    if sent == 'Ø®ÙˆØ´Ø­Ø§Ù„': return 'Hope/Positive'\n",
    "    if sent in ['Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†', 'Ù…Ø¶Ø·Ø±Ø¨']: return 'Despair/Negative'\n",
    "    return 'Neutral'\n",
    "\n",
    "df_results['mood_category'] = df_results['sentiment'].apply(categorize_mood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7f87b",
   "metadata": {},
   "source": [
    "### Calculate percentages per source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_stats = df_results.groupby(['source', 'mood_category']).size().unstack(fill_value=0)\n",
    "mood_stats['Total'] = mood_stats.sum(axis=1)\n",
    "mood_stats['Despair_Rate'] = (mood_stats.get('Despair/Negative', 0) / mood_stats['Total'] * 100).round(1)\n",
    "\n",
    "print(\"\\n--- Mood Statistics per Channel ---\")\n",
    "display(mood_stats)\n",
    "mood_stats.to_csv(os.path.join(RESULTS_DIR, \"final_mood_statistics.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907bcdb",
   "metadata": {},
   "source": [
    "### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_stats[['Hope/Positive', 'Despair/Negative', 'Neutral']].plot(kind='bar', stacked=True, color=['green', 'red', 'gray'], figsize=(10, 6))\n",
    "plt.title(\"Sentiment Distribution by Channel\")\n",
    "plt.ylabel(\"Number of Posts\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"final_mood_barchart.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
