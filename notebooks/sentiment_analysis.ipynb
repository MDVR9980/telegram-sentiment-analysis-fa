{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f3ba9e",
   "metadata": {},
   "source": [
    "# # Sentiment Analysis Test (10 Samples)\n",
    "# Testing the pipeline with a **High-Precision Persian Prompt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc315c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b5f57",
   "metadata": {},
   "source": [
    "## Import modules from 'scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45fc2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.preprocessor import TextPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbef2c",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbbcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "OUTPUT_DIR = \"../data/processed\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "MODEL_NAME = \"llama3\"\n",
    "TARGET_FILE = \"kafiha_messages.csv\" # Example file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e009a4",
   "metadata": {},
   "source": [
    "## Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32076aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(filename, sample_size=None):\n",
    "    \"\"\"\n",
    "    Loads CSV, cleans text FIRST, filters short texts, and THEN samples.\n",
    "    This ensures we get exactly 'sample_size' valid rows.\n",
    "    \"\"\"\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Fill NaNs\n",
    "    df['text'] = df['text'].fillna('')\n",
    "    df['emoji_reactions'] = df['emoji_reactions'].fillna('')\n",
    "    \n",
    "    # Initialize Preprocessor\n",
    "    preprocessor = TextPreprocessor()\n",
    "    \n",
    "    print(f\"Preprocessing all data in {filename} to find valid samples...\")\n",
    "    # Clean all rows first\n",
    "    tqdm.pandas(desc=\"Cleaning Text\")\n",
    "    df['clean_post_text'] = df['text'].progress_apply(preprocessor.clean_text)\n",
    "    df['clean_reactions'] = df['emoji_reactions'].apply(preprocessor.clean_reactions)\n",
    "    \n",
    "    # Filter: Remove short texts (noise) BEFORE sampling\n",
    "    # We increase the threshold to 15 to ensure meaningful sentences\n",
    "    df_clean = df[df['clean_post_text'].str.len() > 15].copy()\n",
    "    \n",
    "    # Now take the sample from the clean pool\n",
    "    if sample_size:\n",
    "        if len(df_clean) >= sample_size:\n",
    "            df_clean = df_clean.head(sample_size).copy()\n",
    "            print(f\"Successfully selected {sample_size} valid samples.\")\n",
    "        else:\n",
    "            print(f\"Warning: Only found {len(df_clean)} valid samples.\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148e8e",
   "metadata": {},
   "source": [
    "## Sentiment Inference with Precise Persian Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text, reactions):\n",
    "    \"\"\"\n",
    "    Uses Few-Shot Prompting to achieve maximum accuracy.\n",
    "    We provide examples to the model so it understands nuances like 'Heartbreak' vs 'Happiness'.\n",
    "    \"\"\"\n",
    "    # Context\n",
    "    prompt_text = f\"متن پست: {text}\\nواکنش‌ها: {reactions}\"\n",
    "    \n",
    "    # --- FEW-SHOT PROMPT (Maximum Accuracy) ---\n",
    "    system_prompt = (\n",
    "        \"تو یک تحلیلگر دقیق احساسات فارسی هستی. بر اساس مثال‌های زیر، پست جدید را طبقه‌بندی کن.\\n\"\n",
    "        \"دسته‌بندی‌ها: ['خوشحال', 'ناراحت', 'عصبانی', 'مضطرب', 'خنثی', 'نگران']\\n\\n\"\n",
    "        \"--- مثال‌های آموزشی ---\\n\"\n",
    "        \"مثال ۱ (تبلیغات/خبر):\\n\"\n",
    "        \"متن: تور استانبول ویژه بلک فرایدی با قیمت مناسب هتل ۵ ستاره.\\n\"\n",
    "        \"برچسب: خنثی\\n\\n\"\n",
    "        \"مثال ۲ (شکست عشقی/غم):\\n\"\n",
    "        \"متن: فراموش کردنت سخته عزیزم، هنوز دوستت دارم ولی نیستی که ببینی.\\n\"\n",
    "        \"برچسب: ناراحت\\n\\n\"\n",
    "        \"مثال ۳ (طنز/خوشحالی):\\n\"\n",
    "        \"متن: بالاخره تموم شد! وای چقدر خوشحالم که این پروژه رو تحویل دادم.\\n\"\n",
    "        \"برچسب: خوشحال\\n\\n\"\n",
    "        \"مثال ۴ (عصبانیت/اعتراض):\\n\"\n",
    "        \"متن: چرا اینقدر وضعیت اینترنت افتضاحه؟ شورشو درآوردن دیگه واقعا خسته شدیم.\\n\"\n",
    "        \"برچسب: عصبانی\\n\\n\"\n",
    "        \"مثال ۵ (نگرانی/اضطراب):\\n\"\n",
    "        \"متن: وای آخر ماه شد و هنوز حقوق نریختن، قسط‌ها رو چیکار کنم؟ استرس دارم.\\n\"\n",
    "        \"برچسب: نگران\\n\\n\"\n",
    "        \"--- پایان مثال‌ها ---\\n\"\n",
    "        \"حالا فقط برچسب پست زیر را بنویس (بدون هیچ توضیح اضافه):\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt_text},\n",
    "        ])\n",
    "        \n",
    "        label = response['message']['content'].strip()\n",
    "        \n",
    "        # Validation\n",
    "        valid_labels = ['خوشحال', 'ناراحت', 'عصبانی', 'مضطرب', 'خنثی', 'نگران']\n",
    "        for v in valid_labels:\n",
    "            if v in label:\n",
    "                return v\n",
    "        # If the model adds punctuation, clean it\n",
    "        for v in valid_labels:\n",
    "            if v in label: return v\n",
    "            \n",
    "        return \"خنثی\" # Fallback\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e7b6e",
   "metadata": {},
   "source": [
    "## 1. Load new data (Exactly 10 samples)\n",
    "### Make sure to run this line again to get the new filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acf531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Analysis on 10 samples...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Analysis on 10 samples...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdf_test\u001b[49m\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39mdf_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      4\u001b[0m     label \u001b[38;5;241m=\u001b[39m get_sentiment(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_post_text\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_reactions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     sentiments\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df_test = load_and_clean_data(TARGET_FILE, sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e58531",
   "metadata": {},
   "source": [
    "## 2. Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning Analysis on 10 samples...\")\n",
    "sentiments = []\n",
    "for index, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
    "    label = get_sentiment(row['clean_post_text'], row['clean_reactions'])\n",
    "    sentiments.append(label)\n",
    "\n",
    "df_test['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfec74",
   "metadata": {},
   "source": [
    "## 3. Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Results ---\")\n",
    "print(df_test[['clean_post_text', 'sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a51b9",
   "metadata": {},
   "source": [
    "# 4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
